@incollection{Alvarez2006,
author = {Alvarez, E. and Cortada, O. and Verdugo, F.},
booktitle = {Seguretat, medi ambient, qualitat a la construcci{\'{o}}: la visi{\'{o}} dels estudiants: curs 2005-06},
isbn = {84-96736-03-2},
pages = {31--45},
publisher = {Centre Internacional de M{\`{e}}todes Num{\`{e}}rics a l ́Enginyeria},
title = {{Excavaci{\'{o}} del tunel de la futura l{\'{i}}nia 9 del Metro de Barcelona}},
year = {2006}
}
@article{badia_2020a,
abstract = {In this work, we present an adaptive unfitted finite element scheme that combines the aggregated finite element method with parallel adaptive mesh refinement. We introduce a novel scalable distributed-memory implementation of the resulting scheme on locally-adapted Cartesian forest-of-trees meshes. We propose a two-step algorithm to construct the finite element space at hand that carefully mixes aggregation constraints of problematic degrees of freedom, which get rid of the small cut cell problem, and standard hanging degree of freedom constraints, which ensure trace continuity on non-conforming meshes. Following this approach, we derive a finite element space that can be expressed as the original one plus well-defined linear constraints. Moreover, it requires minimum parallelization effort, using standard functionality available in existing large-scale finite element codes. Numerical experiments demonstrate its optimal mesh adaptation capability, robustness to cut location and parallel efficiency, on classical Poisson hp-adaptivity benchmarks. Our work opens the path to functional and geometrical error-driven dynamic mesh adaptation with the aggregated finite element method in large-scale realistic scenarios. Likewise, it can offer guidance for bridging other scalable unfitted methods and parallel adaptive mesh refinement.},
archivePrefix = {arXiv},
arxivId = {2006.05373},
author = {Badia, Santiago and Mart{\'{i}}n, Alberto F and Neiva, Eric and Verdugo, Francesc},
eprint = {2006.05373},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Badia et al. - 2020 - THE AGGREGATED UNFITTED FINITE ELEMENT METHOD ON PARALLEL TREE-BASED ADAPTIVE MESHES.pdf:pdf},
issn = {23318422},
journal = {Arxiv preprints},
keywords = {Unfitted finite elements {\textperiodcentered} Algebraic multigrid {\textperiodcentered} A},
title = {{The aggregated unfitted finite element method on parallel tree-based adaptive meshes}},
year = {2020}
}
@article{badia_2019a,
abstract = {We present highly scalable parallel distributed-memory algorithms and associated data structures for a generic finite element framework that supports {\$}h{\$}-adaptivity on computational domains represented as multiple connected adaptive trees, thus providing multi-scale resolution on problems governed by partial differential equations. The framework is grounded on a rich representation of the adaptive mesh suitable for generic finite elements that is built on top of a low-level, light-weight forest-of-trees data structure handled by a specialized, highly parallel adaptive meshing engine. Along the way, we have identified the requirements that the forest-of-trees layer must fulfill to be coupled into our framework. Essentially, it must be able to describe neighboring relationships between cells in the adapted mesh (apart from hierarchical relationships) across the lower-dimensional objects at the boundary of the cells. Atop this two-layered mesh representation, we build the rest of data structures required for the numerical integration and assembly of the discrete system of linear equations. We consider algorithms that are suitable for both subassembled and fully-assembled distributed data layouts of linear system matrices. The proposed framework has been implemented within the FEMPAR scientific software library, using p4est as a practical forest-of-octrees demonstrator. A comprehensive strong scaling study of this implementation when applied to Poisson and Maxwell problems reveals remarkable scalability up to 32.2K CPU cores and 482.2M degrees of freedom. Besides, the implementation in FEMPAR of the proposed approach is up to 2.6 and 3.4 times faster than the state-of-the-art deal.ii finite element software in the {\$}h{\$}-adaptive approximation of a Poisson problem with first- and second-order Lagrangian finite elements, respectively (excluding the linear solver step from the comparison).},
archivePrefix = {arXiv},
arxivId = {1907.03709},
author = {Badia, Santiago and Mart{\'{i}}n, Alberto F. and Neiva, Eric and Verdugo, Francesc},
doi = {10.1137/20M1328786},
eprint = {1907.03709},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Badia et al. - 2019 - A generic finite element framework on parallel tree-based adaptive meshes.pdf:pdf},
journal = {SIAM Journal on Scientific Computing},
number = {6},
pages = {C436--C468},
title = {{A generic finite element framework on parallel tree-based adaptive meshes}},
url = {http://arxiv.org/abs/1907.03709},
volume = {42},
year = {2020}
}
@article{badia_block_2014,
abstract = {The thermally coupled incompressible inductionless magnetohydrodynamics (MHD) problem models the flow of an electrically charged fluid under the influence of an external electromagnetic field with thermal coupling. This system of partial differential equations is strongly coupled and highly nonlinear for real cases of interest. Therefore, fully implicit time integration schemes are very desirable in order to capture the different physical scales of the problem at hand. However, solving the multiphysics linear systems of equations resulting from such algorithms is a very challenging task which requires efficient and scalable preconditioners. In this work, a new family of recursive block LU preconditioners is designed and tested for solving the thermally coupled inductionless MHD equations. These preconditioners are obtained after splitting the fully coupled matrix into one-physics problems for every variable (velocity, pressure, current density, electric potential and temperature) that can be optimally solved, e.g., using preconditioned domain decomposition algorithms. The main idea is to arrange the original matrix into an (arbitrary) 2 × 2 block matrix, and consider an LU preconditioner obtained by approximating the corresponding Schur complement. For every one of the diagonal blocks in the LU preconditioner, if it involves more than one type of unknowns, we proceed the same way in a recursive fashion. This approach is stated in an abstract way, and can be straightforwardly applied to other multiphysics problems. Further, we precisely explain a flexible and general software design for the code implementation of this type of preconditioners. {\textcopyright} 2014 Elsevier Inc.},
author = {Badia, Santiago and Mart{\'{i}}n, Alberto F. and Planas, Ramon},
doi = {10.1016/j.jcp.2014.06.028},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Badia, Mart{\'{i}}n, Planas - 2014 - Block recursive LU preconditioners for the thermally coupled incompressible inductionless MHD problem.pdf:pdf},
issn = {00219991},
journal = {Journal of Computational Physics},
keywords = {Block preconditioning,Inductionless magnetohydrodynamics,Q1,Stabilized finite element methods},
mendeley-tags = {Q1},
month = {oct},
pages = {562--591},
title = {{Block recursive LU preconditioners for the thermally coupled incompressible inductionless MHD problem}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0021999114004355},
volume = {274},
year = {2014}
}
@article{badia_fempar:_2017,
abstract = {FEMPAR is an open source object oriented Fortran200X scientific software library for the high-performance scalable simulation of complex multiphysics problems governed by partial differential equations at large scales, by exploiting state-of-the-art supercomputing resources. It is a highly modularized, flexible, and extensible library, that provides a set of modules that can be combined to carry out the different steps of the simulation pipeline. FEMPAR includes a rich set of algorithms for the discretization step, namely (arbitrary-order) grad, div, and curl-conforming finite element methods, discontinuous Galerkin methods, B-splines, and unfitted finite element techniques on cut cells, combined with {\$}h{\$}-adaptivity. The linear solver module relies on state-of-the-art bulk-asynchronous implementations of multilevel domain decomposition solvers for the different discretization alternatives and block-preconditioning techniques for multiphysics problems. FEMPAR is a framework that provides users with out-of-the-box state-of-the-art discretization techniques and highly scalable solvers for the simulation of complex applications, hiding the dramatic complexity of the underlying algorithms. But it is also a framework for researchers that want to experience with new algorithms and solvers, by providing a highly extensible framework. In this work, the first one in a series of articles about FEMPAR, we provide a detailed introduction to the software abstractions used in the discretization module and the related geometrical module. We also provide some ingredients about the assembly of linear systems arising from finite element discretizations, but the software design of complex scalable multilevel solvers is postponed to a subsequent work.},
archivePrefix = {arXiv},
arxivId = {1708.01773},
author = {Badia, Santiago and Mart{\'{i}}n, Alberto F. and Principe, Javier},
doi = {10.1007/s11831-017-9244-1},
eprint = {1708.01773},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Badia, Mart{\'{i}}n, Principe - 2018 - FEMPAR An Object-Oriented Parallel Finite Element Framework.pdf:pdf},
issn = {18861784},
journal = {Archives of Computational Methods in Engineering},
keywords = {Q1},
mendeley-tags = {Q1},
month = {oct},
number = {2},
pages = {195--271},
shorttitle = {FEMPAR},
title = {{FEMPAR: An Object-Oriented Parallel Finite Element Framework}},
volume = {25},
year = {2018}
}
@article{badia_2016,
abstract = {In this paper we present a fully distributed, communicator-aware, recursive, and interlevel-overlapped message-passing implementation of the multilevel balancing domain decomposition by constraints (MLBDDC) preconditioner. The implementation highly relies on subcommunicators in order to achieve the desired effect of coarse-grain overlapping of computation and communication, and communication and communication among levels in the hierarchy (namely, interlevel overlapping). Essentially, the main communicator is split into as many nonoverlapping subsets of message-passing interface (MPI) tasks (i.e., MPI subcommunicators) as levels in the hierarchy. Provided that specialized resources (cores and memory) are devoted to each level, a careful rescheduling and mapping of all the computations and communications in the algorithm lets a high degree of overlapping be exploited among levels. All subroutines and associated data structures are expressed recursively, and therefore MLBDDC preconditioners with an arbitrary number of levels can be built while re-using significant and recurrent parts of the codes. This approach leads to excellent weak scalability results as soon as level-1 tasks can fully overlap coarser-levels duties. We provide a model to indicate how to choose the number of levels and coarsening ratios between consecutive levels and determine qualitatively the scalability limits for a given choice. We have carried out a comprehensive weak scalability analysis of the proposed implementation for the three-dimensional Laplacian and linear elasticity problems on structured and unstructured meshes. Excellent weak scalability results have been obtained up to 458,752 IBM BG/Q cores and 1.8 million MPI being, being the first time that exact domain decomposition preconditioners (only based on sparse direct solvers) reach these scales.},
author = {Badia, Santiago and Mart{\'{i}}n, Alberto F. and Principe, Javier},
doi = {10.1137/15M1013511},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Badia, Mart{\'{i}}n, Principe - 2016 - Multilevel Balancing Domain Decomposition at Extreme Scales.pdf:pdf},
journal = {SIAM Journal on Scientific Computing},
keywords = {Domain decomposition,Finite elements,High-performance computing,Parallel computing,Perdominant preconditioning,Q1,Scientific software},
mendeley-tags = {Q1},
number = {1},
pages = {C22----C52},
title = {{Multilevel Balancing Domain Decomposition at Extreme Scales}},
volume = {38},
year = {2016}
}
@article{Badia2008,
abstract = {In this article we address the numerical simulation of fluid-structure interaction (FSI) problems featuring large added-mass effect. We analyze different preconditioners for the coupled system matrix obtained after space-time discretization and linearization of the FSI problem. The classical Dirichlet-Neumann preconditioner has the advantage of "modularity" because it allows to reuse existing fluid and structure codes with minimum effort (simple interface communication). Unfortunately, its performance is very poor in case of large added-mass effects. Alternatively, we consider two non-modular approaches. The first one consists in preconditioning the coupled system with a suitable diagonal scaling combined with an ILUT preconditioner. The system is then solved by a Krylov method. The drawback of this procedure is that the combination of fluid and structure codes to solve the coupled system is not straightforward. The second non-modular approach we consider is a splitting technique based on an inexact block-LU factorization of the linear FSI system. The resulting algorithm computes the fluid velocity separately from the coupled pressure-structure system at each iteration, reducing the computational cost. Independently of the preconditioner, the efficiency of semi-implicit algorithms (i.e., those that treat geometric and fluid nonlinearities in an explicit way) is highlighted and their performance compared to the one of implicit algorithms. All the methods are tested on three-dimensional blood-vessel systems. The algorithm combining the non-modular ILUT preconditioner with Krylov methods proved to be the fastest. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {1709.09052},
author = {Badia, Santiago and Quaini, Annalisa and Quarteroni, Alfio},
doi = {10.1016/j.cma.2008.04.018},
eprint = {1709.09052},
issn = {00457825},
journal = {Computer Methods in Applied Mechanics and Engineering},
keywords = {Added-mass effect,Fluid-structure interaction,Hemodynamics,Partitioned procedures,Preconditioners,Semi-implicit coupling},
month = {sep},
number = {49-50},
pages = {4216--4232},
publisher = {North-Holland},
title = {{Modular vs. non-modular preconditioners for fluid-structure systems with large added-mass effect}},
url = {https://www.sciencedirect.com/science/article/pii/S0045782508001758?via{\%}3Dihub},
volume = {197},
year = {2008}
}
@article{badia_2017,
abstract = {Unfitted finite element methods, e.g., extended finite element techniques or the so-called finite cell method, have a great potential for large scale simulations, since they avoid the generation of body-fitted meshes and the use of graph partitioning techniques, two main bottlenecks for problems with non-trivial geometries. However, the linear systems that arise from these discretizations can be much more ill-conditioned, due to the so-called small cut cell problem. The state-of-the-art approach is to rely on sparse direct methods, which have quadratic complexity and are thus not well suited for large scale simulations. In order to solve this situation, in this work we investigate the use of domain decomposition preconditioners (balancing domain decomposition by constraints) for unfitted methods. We observe that a straightforward application of these preconditioners to the unfitted case has a very poor behavior. As a result, we propose a customization of the classical BDDC methods based on the stiffness weighting operator and an improved definition of the coarse degrees of freedom in the definition of the preconditioner. These changes lead to a robust and algorithmically scalable solver able to deal with unfitted grids. A complete set of complex 3D numerical experiments shows the good performance of the proposed preconditioners.},
archivePrefix = {arXiv},
arxivId = {1703.06323},
author = {Badia, Santiago and Verdugo, Francesc},
doi = {10.1016/j.cam.2017.09.034},
eprint = {1703.06323},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Badia, Verdugo - 2018 - Robust and scalable domain decomposition solvers for unfitted finite element methods.pdf:pdf},
issn = {03770427},
journal = {Journal of Computational and Applied Mathematics},
keywords = {Domain decomposition,Embedded boundary methods,Linear solvers,Mathematics - Numerical Analysis,Parallel computing,Q1,Unfitted finite elements},
mendeley-tags = {Q1},
month = {oct},
pages = {740--759},
publisher = {North-Holland},
title = {{Robust and scalable domain decomposition solvers for unfitted finite element methods}},
url = {http://arxiv.org/abs/1703.06323 http://www.sciencedirect.com/science/article/pii/S037704271730465X},
volume = {344},
year = {2018}
}
@article{badia_2020b,
abstract = {Gridap is a new Finite Element (FE) framework, exclusively written in the Julia programming language, for the numerical simulation of a wide range of mathematical models governed by partial differential equations (PDEs). The library provides a feature-rich set of discretization techniques, including continuous and discontinuous FE methods with Lagrangian, Raviart-Thomas, or N{\'{e}}d{\'{e}}lec interpolations, and supports a wide range of problem types including linear, nonlinear, single-field, and multi-field PDEs (see (Badia, Mart{\'{i}}n, {\&} Principe, 2018, Section 3) for a detailed presentation of the mathematical abstractions behind the implementation of these FE methods). Gridap is designed to help application experts to easily simulate real-world problems, to help researchers improve productivity when developing new FE-related techniques, and also for its usage in numerical PDE courses. The main motivation behind Gridap is to find an improved balance between computational performance, user-experience, and work-flow productivity when working with FE libraries. Previous FE frameworks, e.g., FEniCS (Alnaes et al., 2015) or Deal.II (Bangerth, Hartmann, {\&} Kanschat, 2007) usually provides a high-level user front-end to facilitate the use of the library and a computational back-end to achieve performance. The user front-end is usually programmable in an interpreted language like Python, whereas the computational back-end is usually coded in a compiled language like C/C++ or Fortran. Users can benefit from the high-level front-end (i.e., for rapid prototyping) and simultaneously enjoy the performance of the compiled back-end. This approach reaches a compromise between performance and productivity when the back-end provides all the functionality required by the user. However, it does not satisfactorily address the needs of researchers on numerical methods willing to extend the library with new techniques or features. These extensions usually need to be done at the level of the computational back-end for performance reasons.},
author = {Badia, Santiago and Verdugo, Francesc},
doi = {10.21105/joss.02520},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Badia, Verdugo - 2020 - Gridap An extensible Finite Element toolbox in Julia.pdf:pdf},
issn = {2475-9066},
journal = {Journal of Open Source Software},
month = {aug},
number = {52},
pages = {2520},
publisher = {The Open Journal},
title = {{Gridap: An extensible Finite Element toolbox in Julia}},
url = {https://joss.theoj.org/papers/10.21105/joss.02520},
volume = {5},
year = {2020}
}
@article{badia_2018a,
abstract = {Unfitted finite element techniques are valuable tools in different applications where the generation of body-fitted meshes is difficult. However, these techniques are prone to severe ill conditioning problems that obstruct the efficient use of iterative Krylov methods and, in consequence, hindersthe practical usage of unfitted methods for realistic large scale applications. In this work, we present a technique that addresses such conditioning problems by constructing enhanced finite element spaces based on a cell aggregation technique. The presented method, called aggregated unfitted finite element method, is easy to implement, and can be used, in contrast to previous works, in Galerkin approximations of coercive problems with conforming Lagrangian finite element spaces. The mathematical analysis of the method states that the condition number of the resulting linear system matrix scales as in standard finite elements for body-fitted meshes, without being affected by small cut cells, and that the method leads to the optimal finite element convergence order. These theoretical results are confirmed with 2D and 3D numerical experiments.},
archivePrefix = {arXiv},
arxivId = {1709.09122},
author = {Badia, Santiago and Verdugo, Francesc and Mart{\'{i}}n, Alberto F.},
doi = {10.1016/j.cma.2018.03.022},
eprint = {1709.09122},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Badia, Verdugo, Mart{\'{i}}n - 2018 - The aggregated unfitted finite element method for elliptic problems.pdf:pdf},
issn = {00457825},
journal = {Computer Methods in Applied Mechanics and Engineering},
keywords = {Embedded boundary methods,Ill-conditioning,Q1,Unfitted finite elements},
mendeley-tags = {Q1},
month = {jul},
pages = {533--553},
title = {{The aggregated unfitted finite element method for elliptic problems}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782518301476},
volume = {336},
year = {2018}
}
@inproceedings{Baker2011,
abstract = {Algebraic multigrid (AMG) solvers have proven to be extremely efficient on distributed-memory architectures. However, when executed on modern multicore cluster architectures, we face new challenges that can significantly harm AMG's performance. We discuss our experiences on such an architecture and present a set of techniques that help users to overcome the associated problems, including thread and process pinning and correct memory associations. We have implemented most of the techniques in a MultiCore SUPport library (MCSup), which helps to map OpenMP applications to multicore machines. We present results using both an MPI-only and a hybrid MPI/OpenMP model.},
author = {Baker, Allison H and Schulz, Martin and Yang, Ulrike M},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-19328-6_12},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baker, Schulz, Yang - 2011 - On the performance of an algebraic multigrid solver on multicore clusters.pdf:pdf},
isbn = {9783642193279},
issn = {03029743},
pages = {102--115},
title = {{On the performance of an algebraic multigrid solver on multicore clusters}},
url = {https://computation.llnl.gov/projects/hypre-scalable-linear-solvers-multigrid-methods/Baker-2011-VECPAR.pdf},
volume = {6449 LNCS},
year = {2011}
}
@techreport{petsc-user-ref,
annote = {http://www.mcs.anl.gov/petsc},
author = {Balay, Satish and Abhyankar, Shrirang and Adams, Mark{\~{}}F. and Brown, Jed and Brune, Peter and Buschelman, Kris and Dalcin, Lisandro and Dener, Alp and Eijkhout, Victor and Gropp, William{\~{}}D. and Kaushik, Dinesh and Knepley, Matthew{\~{}}G. and May, Dave{\~{}}A. and McInnes, Lois Curfman and Mills, Richard Tran and Munson, Todd and Rupp, Karl and Sanan, Patrick and Smith, Barry{\~{}}F. and Zampini, Stefano and Zhang, Hong and Zhang, Hong},
howpublished = {http://www.mcs.anl.gov/petsc},
institution = {Argonne National Laboratory},
number = {ANL-95/11 - Revision 3.10},
title = {{PETSc Users Manual}},
url = {http://www.mcs.anl.gov/petsc},
year = {2018}
}
@article{Bangerth2007,
abstract = {An overview of the software design and data abstraction decisions chosen for deal.II, a general purpose finite element library written in C++, is given. The library uses advanced object-oriented and data encapsulation techniques to break finite element implementations into smaller blocks that can be arranged to fit users requirements. Through this approach, deal.II supports a large number of different applications covering a wide range of scientific areas, programming methodologies, and application-specific algorithms, without imposing a rigid framework into which they have to fit. A judicious use of programming techniques allows us to avoid the computational costs frequently associated with abstract object-oriented class libraries. The paper presents a detailed description of the abstractions chosen for defining geometric information of meshes and the handling of degrees of freedom associated with finite element spaces, as well as of linear algebra, input/output capabilities and of interfaces to other software, such as visualization tools. Finally, some results obtained with applications built atop deal.II are shown to demonstrate the powerful capabilities of this toolbox. {\textcopyright} 2007 ACM.},
author = {Bangerth, W. and Hartmann, R. and Kanschat, G.},
doi = {10.1145/1268776.1268779},
isbn = {0098-3500},
issn = {00983500},
journal = {ACM Transactions on Mathematical Software},
keywords = {Object-orientation,Software design},
month = {aug},
number = {4},
publisher = {ACM},
title = {{Deal.II --A general-purpose object-oriented finite element library}},
url = {http://portal.acm.org/citation.cfm?doid=1268776.1268779},
volume = {33},
year = {2007}
}
@article{becker_2001,
abstract = {This article surveys a general approach to error control and adaptive mesh design in Galerkin finite element methods that is based on duality principles as used in optimal control. Most of the existing work on a posteriori error analysis deals with error estimation in global norms like the ‘energy norm' or the L2 norm, involving usually unknown ‘stability constants'. However, in most applications, the error in a global norm does not provide useful bounds for the errors in the quantities of real physical interest. Further, their sensitivity to local error sources is not properly represented by global stability constants. These deficiencies are overcome by employing duality techniques, as is common in a priori error analysis of finite element methods, and replacing the global stability constants by computationally obtained local sensitivity factors. Combining this with Galerkin orthogonality, a posteriori estimates can be derived directly for the error in the target quantity. In these estimates local residuals of the computed solution are multiplied by weights which measure the dependence of the error on the local residuals. Those, in turn, can be controlled by locally refining or coarsening the computational mesh. The weights are obtained by approximately solving a linear adjoint problem. The resulting a posteriori error estimates provide the basis of a feedback process for successively constructing economical meshes and corresponding error bounds tailored to the particular goal of the computation. This approach, called the ‘dual-weighted-residual method', is introduced initially within an abstract functional analytic setting, and is then developed in detail for several model situations featuring the characteristic properties of elliptic, parabolic and hyperbolic problems. After having discussed the basic properties of duality-based adaptivity, we demonstrate the potential of this approach by presenting a selection of results obtained for practical test cases. These include problems from viscous fluid flow, chemically reactive flow, elasto-plasticity, radiative transfer, and optimal control. Throughout the paper, open theoretical and practical problems are stated together with references to the relevant literature.},
address = {Cambridge},
author = {Becker, Roland and Rannacher, Rolf},
doi = {10.1017/S0962492901000010},
editor = {Iserles, A},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Becker, Rannacher - 2001 - An optimal control approach to a posteriori error estimation in finite element methods.html:html},
journal = {Acta Numerica},
keywords = {Error,Goal{\_}oriented},
month = {may},
pages = {1--102},
publisher = {Cambridge University Press},
title = {{An optimal control approach to a posteriori error estimation in finite element methods}},
volume = {10},
year = {2001}
}
@article{berger-vergiat_inexact_2012,
abstract = {Traditional algebraic multigrid (AMG) preconditioners are not well suited for crack problems modeled by extended finite element methods (XFEM). This is mainly because of the unique XFEM formulations, which embed discontinuous fields in the linear system by addition of special degrees of freedom. These degrees of freedom are not properly handled by the AMG coarsening process and lead to slow convergence. In this paper, we proposed a simple domain decomposition approach that retains the AMG advantages on well-behaved domains by avoiding the coarsening of enriched degrees of freedom. The idea was to employ a multiplicative Schwarz preconditioner where the physical domain was partitioned into “healthy” (or unfractured) and “cracked” subdomains. First, the “healthy” subdomain containing only standard degrees of freedom, was solved approximately by one AMG V-cycle, followed by concurrent direct solves of “cracked” subdomains. This strategy alleviated the need to redesign special AMG coarsening strategies that can handle XFEM discretizations. Numerical examples on various crack problems clearly illustrated the superior performance of this approach over a brute force AMG preconditioner applied to the linear system. Copyright {\textcopyright} 2011 John Wiley {\&} Sons, Ltd.},
author = {Berger-Vergiat, Luc and Waisman, Haim and Hiriyur, Badri and Tuminaro, Ray and Keyes, David},
doi = {10.1002/nme.3318},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berger-Vergiat et al. - 2012 - Inexact Schwarz-algebraic multigrid preconditioners for crack problems modeled by extended finite element.pdf:pdf},
issn = {1097-0207},
journal = {International Journal for Numerical Methods in Engineering},
keywords = {X-FEM,domain decomposition,multigrid},
month = {apr},
number = {3},
pages = {311--328},
title = {{Inexact Schwarz-algebraic multigrid preconditioners for crack problems modeled by extended finite element methods}},
volume = {90},
year = {2012}
}
@article{Bezanson2017,
abstract = {Bridging cultures that have often been distant, Julia combines expertise from the diverse fields of computer science and computational science to create a new approach to numerical computing. Julia is designed to be easy and fast. Julia questions notions generally held as "laws of nature" by practitioners of numerical computing: 1. High-level dynamic programs have to be slow. 2. One must prototype in one language and then rewrite in another language for speed or deployment, and 3. There are parts of a system for the programmer, and other parts best left untouched as they are built by the experts. We introduce the Julia programming language and its design --- a dance between specialization and abstraction. Specialization allows for custom treatment. Multiple dispatch, a technique from computer science, picks the right algorithm for the right circumstance. Abstraction, what good computation is really about, recognizes what remains the same after differences are stripped away. Abstractions in mathematics are captured as code through another technique from computer science, generic programming. Julia shows that one can have machine performance without sacrificing human convenience.},
author = {Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B.},
doi = {10.1137/141000671},
issn = {00361445},
journal = {SIAM Review},
keywords = {Julia,Numerical,Parallel,Scientific computing},
number = {1},
pages = {65--98},
publisher = {Society for Industrial and Applied Mathematics Publications},
title = {{Julia: A fresh approach to numerical computing}},
volume = {59},
year = {2017}
}
@book{briggs_2000,
abstract = {Twelve years have passed since the publication of the first edition of A Multigrid Tutorial. During those years, the field of multigrid and multilevel methods has expanded at a tremendous rate, reflecting progress in the development and analysis of algorithms and in the evolution of computing environments. Because of these changes, the first edition of the book has become increasingly outdated and the need for a new edition has become quite apparent. With the overwhelming growth in the subject, an area in which I have never done serious research, I felt remarkably unqualified to attempt a new edition. Realizing that I needed some help, I recruited two experts to assist with the project. Steve McCormick (Department of Applied Mathematics, University of Colorado at Boulder) is one of the original researchers in the field of multigrid methods and the real instigator of the first edition. There could be no better collaborator on the subject. Van Emden Henson (Center for Applied Scientific Computing, Lawrence Livermore National Laboratory) has specialized in applications of multigrid methods, with a particular emphasis on algebraic multigrid methods. Our collaboration on a previous SIAM monograph made him an obvious choice as a co-author. With the team in place, we began deliberating on the content of the new edition. It was agreed that the first edition should remain largely intact with little more than some necessary updating. Our aim was to add a roughly equal amount of new material that reflects important core developments in the field. A topic that probably should have been in the first edition comprises Chapter 6: FAS (Full Approximation Scheme), which is used for nonlinear problems. Chapter 7 is a collection of methods for four special situations that arise frequently in solving boundary value problems: Neumann boundary conditions, anisotropic problems, variable-mesh problems, and variable-coefficient problems. One of the chief motivations for writing a second edition was the recent surge of interest in algebraic multigrid methods, which is the subject of Chapter 8. In Chapter 9, we attempt to explain the complex subject of adaptive grid methods, as it appears in the FAC (Fast Adaptive Composite) Grid Method. Finally, in Chapter 10, we depart from the predominantly finite difference approach of the book and show how finite element formulations arise. This chapter provides a natural closing because it ties a knot in the thread of variational principles that runs through much of the book.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Briggs, William L. and Henson, Van Emden and McCormick, Steve F.},
doi = {10.1137/1.9780898719505},
eprint = {arXiv:1011.1669v3},
isbn = {978-0-89871-462-3},
issn = {0169-2070},
month = {jan},
pmid = {18301595},
publisher = {Society for Industrial and Applied Mathematics},
title = {{A Multigrid Tutorial, Second Edition}},
url = {http://epubs.siam.org/doi/book/10.1137/1.9780898719505},
year = {2000}
}
@techreport{brommel_juqueen_2015,
abstract = {In conjunction with this year's JUQUEEN Porting and Tuning Workshop, which is part of the PRACE Advanced Training Centres curriculum, JSC continued its series of BlueGene Extreme Scaling Workshops. Seven application teams were invited to stay for two days and work on the scalability of their codes, with dedicated access to the entire JUQUEEN system for a period of 30 hours. Most of the teams' codes had thematic overlap with JSC Simulation Laboratories or were part of an ongoing collaboration with one of the SimLabs. The code teams came from the fields of climate science (ICON from DKRZ, and MPAS-A from KIT and NCAR), engineering (FEMPAR from UPC, and ex$\backslash${\_}nl/FE{\{}$\backslash$textasciicircum{\}}2 from Uni Cologne and TU Freiberg), fluid dynamics (psOpen and SHOCK both from RWTH Aachen), and neuroscience (CoreNeuron from the EPFL Blue Brain Project) and were supported by JSC SimLabs and Cross-sectional teams, with IBM and JUQUEEN technical support. Within the first 24 hours of dedicated access to the entire 28 racks, all seven teams had adapted their codes and datasets to exploit the massive parallelism and restricted node memory for successful executions using all 458,752 cores. Most of them also demonstrated excellent strong or weak scalability, qualifying all but one for the High-Q Club. A total of 370 'large' jobs were executed using 12 of the 15 million core-hours of compute time allocated for the workshop. Detailed results for each code, provided by the application teams themselves, is introduced by analysis comparing them to the other 16 High-Q Club codes. Br{\"{o}}mmel, Dirk; Frings, Wolfgang; Wylie, Brian J. N.},
author = {Br{\"{o}}mmel, Dirk and Wylie, Brian J N and Frings, Wolfgang},
institution = {J{\"{u}}lich Supercomputing Center},
number = {FZJ-2015-01645, FZJ-JSC-IB-2015-01},
title = {{JUQUEEN Extreme Scaling Workshop 2015}},
url = {http://juser.fz-juelich.de/record/188191},
year = {2015}
}
@article{burstedde_p4est_2011,
abstract = {We present scalable algorithms for parallel adaptive mesh refinement and coarsening (AMR), partitioning, and 2:1 balancing on computational domains composed of multiple connected two-dimensional quadtrees or three-dimensional octrees, referred to as a forest of octrees. By dis- tributing the union of octants from all octrees in parallel, we combine the high scalability proven previously for adaptive single-octree algorithms with the geometric flexibility that can be achieved by arbitrarily connected hexahedral macromeshes, in which each macroelement is the root of an adapted octree. A key concept of our approach is an encoding scheme of the interoctree connectivity that permits arbitrary relative orientations between octrees. Based on this encoding we develop interoctree transformations of octants. These form the basis for high-level parallel octree algorithms, which are designed to interact with an application code such as a numerical solver for partial differ- ential equations. We have implemented and tested these algorithms in the p4est software library. We demonstrate the parallel scalability of p4est on its own and in combination with two geophysics codes. Using p4est we generate and adapt multioctree meshes with up to 5.13 × 1011 octants on as many as 220,320 CPU cores and execute the 2:1 balance algorithm in less than 10 seconds per million octants per process.},
author = {Burstedde, Carsten and Wilcox, Lucas C. and Ghattas, Omar},
doi = {10.1137/100791634},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Burstedde, Wilcox, Ghattas - 2011 - p4est Scalable Algorithms for Parallel Adaptive Mesh Refinement on Forests of Octrees.html:html;:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Burstedde, Wilcox, Ghattas - 2011 - p4est Scalable Algorithms for Parallel Adaptive Mesh Refinement on Forests of Octrees(2).pdf:pdf},
isbn = {10648275},
journal = {SIAM Journal on Scientific Computing},
keywords = {10,100791634,1137,65D18,65Y05,65d18,65m50,65y05,68W10,68w10,Morton code,ams subject classifications,doi,forest of octrees,large-scale scientific computing,morton code,parallel adaptive mesh refinement,rithms,scalable algo-,scalable algo-rithms},
number = {3},
pages = {1103--1133},
pmid = {67712640},
shorttitle = {p4est},
title = {{p4est: Scalable Algorithms for Parallel Adaptive Mesh Refinement on Forests of Octrees}},
volume = {33},
year = {2011}
}
@techreport{Casadei2011a,
author = {Casadei, Folco and D{\'{i}}ez, Pedro and Verdugo, Francesc},
institution = {JRC technical notes, European Union},
title = {{Testing adaptivity in 2D cell centred finite volumes with the CDEM combustion model in EUROPLEXUS}},
year = {2011}
}
@techreport{Casadei2010,
author = {Casadei, Folco and D{\'{i}}ez, Pedro and Verdugo, Francesc},
institution = {JRC technical notes, European Union},
title = {{Adaptivity in FE models for fluids in EUROPLEXUS}},
year = {2010}
}
@article{casadei_2013,
abstract = {A procedure to locally refine and un-refine an unstructured computational grid of four-node quadrilaterals (in 2D) or of eight-node hexahedra (in 3D) is presented. The chosen refinement strategy generates only elements of the same type as their parents, but also produces so-called hanging nodes along nonconforming element-to-element interfaces. Continuity of the solution across such interfaces is enforced strongly by Lagrange multipliers. The element split and un-split algorithm is entirely integer-based. It relies only upon element connectivity and makes no use of nodal coordinates or other real-number quantities. The chosen data structure and the continuous tracking of the nature of each node facilitate the treatment of natural and essential boundary conditions in adaptivity. A generalization of the concept of neighbor elements allows transport calculations in adaptive fluid calculations. The proposed procedure is tested in structure and fluid wave propagation problems in explicit transient dynamics.},
author = {Casadei, Folco and D{\'{i}}ez, Pedro and Verdugo, Francesc},
doi = {10.1142/S0219876213500187},
issn = {0219-8762},
journal = {International Journal of Computational Methods},
keywords = {Q3},
mendeley-tags = {Q3},
month = {apr},
number = {04},
pages = {1350018},
title = {{An algorithm for mesh refinement and un-refinement in fast transient dynamics}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S0219876213500187},
volume = {10},
year = {2013}
}
@techreport{Casadei2011,
author = {Casadei, Folco and D{\'{i}}ez, Pedro and Verdugo, Francesc},
institution = {JRC technical notes, European Union},
title = {{Implementation of adaptivity in 3D cell centred finite volumes in EUROPLEXUS}},
year = {2011}
}
@techreport{Casadei2011b,
author = {Casadei, Folco and D{\'{i}}ez, Pedro and Verdugo, Francesc},
howpublished = {JRC technical notes},
institution = {JRC technical notes, European Union},
series = {JRC technical notes},
title = {{Implementation of adaptivity in 2D cell centred finite volumes in EUROPLEXUS}},
year = {2011}
}
@techreport{Casadei2010a,
author = {Casadei, Folco and D{\'{i}}ez, Pedro and Verdugo, Francesc},
institution = {JRC technical notes, European Union},
title = {{A data structure for adaptivity in EUROPLEXUS}},
year = {2010}
}
@techreport{Casadei2011d,
author = {Casadei, Folco and D{\'{i}}ez, Pedro and Verdugo, Francesc},
institution = {JRC technical notes. European Union},
title = {{Adaptive 3D Refinement and Un-refinement of 8-node Solid and Fluid Hexahedra in EUROPLEXUS}},
year = {2011}
}
@techreport{Casadei2011c,
author = {Casadei, Folco and D{\'{i}}ez, Pedro and Verdugo, Francesc},
institution = {JRC technical notes. European Union},
title = {{Implementation of a 2D Adaptivity Indicator for Fast Transient Dynamics in EUROPLEXUS}},
year = {2011}
}
@techreport{Casadei2011e,
author = {Casadei, Folco and D{\'{i}}ez, Pedro and Verdugo, Francesc},
institution = {JRC technical notes. European Union},
title = {{Further Development of 2D Adaptivity Error Indicators in EUROPLEXUS}},
year = {2011}
}
@article{Causin2005,
abstract = {The aim of this work is to provide a mathematical contribution to explain the numerical instabilities encountered under certain combinations of physical parameters in the simulation of fluid-structure interaction (FSI) when using loosely coupled time advancing schemes. It is also shown how the same combinations of parameters lead, in the case of strongly coupled schemes, to problems that demand a greater computational effort to be solved, requiring for example a high number of subiterations. The application that we have in mind is FSI simulation for blood flow in large human arteries, but the discussion applies as well to several FSI problems in which an incompressible fluid interacts with a thin elastic structure. To carry out the mathematical analysis, we consider a simplified model representing the interaction between a potential fluid and a linear elastic thin tube. Despite its simplicity, this model reproduces propagation phenomena and takes into account the added-mass effect of the fluid on the structure, which is known to be source of numerical difficulties. This allows to draw conclusions that apply to more realistic problems, as well. {\textcopyright} 2005 Elsevier B.V. All rights reserved.},
author = {Causin, P. and Gerbeau, J. F. and Nobile, Fabio},
doi = {10.1016/j.cma.2004.12.005},
isbn = {0045-7825},
issn = {00457825},
journal = {Computer Methods in Applied Mechanics and Engineering},
keywords = {Blood flow simulation,Fluid-structure interaction,Numerical stability,Partitioned algorithms},
month = {oct},
number = {42-44},
pages = {4506--4527},
pmid = {14720320},
publisher = {North-Holland},
title = {{Added-mass effect in the design of partitioned algorithms for fluid-structure problems}},
url = {https://www.sciencedirect.com/science/article/pii/S0045782504005328?via{\%}3Dihub},
volume = {194},
year = {2005}
}
@book{cottrell_2009,
abstract = {"This is the most beautiful scientific book that I have ever seen. (I am excluding popular science books from this statement; this book matches some of them in its beauty.) The authors, editors and publishers should be congratulated for giving so much attention not just to the content but also to the way the book looks. It is extremely inviting to read." (Iacm Expressions, 1 October 2010). ISOGEOMETRIC ANALYSIS -- Contents -- Preface -- 1 From CAD and FEA to Isogeometric Analysis: An Historical Perspective -- 1.1 Introduction -- 1.1.1 The need for isogeometric analysis -- 1.1.2 Computational geometry -- 1.2 The evolution of FEA basis functions -- 1.3 The evolution of CAD representations -- 1.4 Things you need to get used to in order to understand NURBS-based isogeometric analysis -- Notes -- 2 NURBS as a Pre-analysis Tool: Geometric Design and Mesh Generation -- 2.1 B-splines -- 2.1.1 Knot vectors -- 2.1.2 Basis functions -- 2.1.3 B-spline geometries -- 2.1.4 Refinement -- 2.2 Non-Uniform Rational B-Splines -- 2.2.1 The geometric point of view -- 2.2.2 The algebraic point of view -- 2.3 Multiple patches -- 2.4 Generating a NURBS mesh: a tutorial -- 2.4.1 Preliminary considerations -- 2.4.2 Selection of polynomial orders -- 2.4.3 Selection of knot vectors -- 2.4.4 Selection of control points -- 2.5 Notation -- Appendix 2.A: Data for the bent pipe -- Notes -- 3 NURBS as a Basis for Analysis: Linear Problems -- 3.1 The isoparametric concept -- 3.1.1 Defining functions on the domain -- 3.2 Boundary value problems (BVPs) -- 3.3 Numerical methods -- 3.3.1 Galerkin -- 3.3.2 Collocation -- 3.3.3 Least-squares -- 3.3.4 Meshless methods -- 3.4 Boundary conditions -- 3.4.1 Dirichlet boundary conditions -- 3.4.2 Neumann boundary conditions -- 3.4.3 Robin boundary conditions -- 3.5 Multiple patches revisited -- 3.5.1 Local refinement -- 3.5.2 Arbitrary topologies -- 3.6 Comparing isogeometric analysis with classical finite element analysis -- 3.6.1 Code architecture -- 3.6.2 Similarities and differences -- Appendix 3.A: Shape function routine -- Appendix 3.B: Error estimates -- Notes -- 4 Linear Elasticity -- 4.1 Formulating the equations of elastostatics -- 4.1.1 Strong form -- 4.1.2 Weak form -- 4.1.3 Galerkin's method -- 4.1.4 Assembly. 4.2 Infinite plate with circular hole under constant in-plane tension -- 4.3 Thin-walled structures modeled as solids -- 4.3.1 Thin cylindrical shell with fixed ends subjected to constant internal pressure -- 4.3.2 The shell obstacle course -- 4.3.3 Hyperboloidal shell -- 4.3.4 Hemispherical shell with a stiffener -- Appendix 4.A: Geometrical data for the hemispherical shell -- Appendix 4.B: Geometrical data for a cylindrical pipe -- Appendix 4.C: Element assembly routine -- Notes -- 5 Vibrations andWave Propagation -- 5.1 Longitudinal vibrations of an elastic rod -- 5.1.1 Formulating the problem -- 5.1.2 Results: NURBS vs. FEA -- 5.1.3 Analytically computing the discrete spectrum -- 5.1.4 Lumped mass approaches -- 5.2 Rotation-free analysis of the transverse vibrations of a Bernoulli-Euler beam -- 5.3 Transverse vibrations of an elastic membrane -- 5.3.1 Linear and nonlinear parameterizations revisited -- 5.3.2 Formulation and results -- 5.4 Rotation-free analysis of the transverse vibrations of a Poisson-Kirchhoff plate -- 5.5 Vibrations of a clamped thin circular plate using three-dimensional solid elements ¯B -- 5.5.1 Formulating the problem -- 5.5.2 Results -- 5.6 The NASA aluminum testbed cylinder -- 5.7 Wave propagation -- 5.7.1 Dispersion analysis -- 5.7.2 Duality principle -- Appendix 5.A: Kolmogorov n-widths -- Notes -- 6 Time-Dependent Problems -- 6.1 Elastodynamics -- 6.2 Semi-discrete methods -- 6.2.1 Matrix formulation -- 6.2.2 Viscous damping -- 6.2.3 Predictor/multicorrector Newmark algorithms -- 6.3 Space-time finite elements -- 7 Nonlinear Isogeometric Analysis -- 7.1 The Newton-Raphson method -- 7.2 Isogeometric analysis of nonlinear differential equations -- 7.2.1 Nonlinear heat conduction -- 7.2.2 Applying the Newton-Raphson method -- 7.2.3 Nonlinear finite element analysis. 11.1 The Cahn-Hilliard equation -- 11.1.1 The strong form -- 11.1.2 The dimensionless strong form -- 11.1.3 The weak form -- 11.2 Numerical results -- 11.2.1 A two-dimensional example -- 11.2.2 A three-dimensional example -- 11.3 The continuous/discontinuous Galerkin (CDG) method -- Note -- 12 Some Additional Geometry -- 12.1 The polar form of polynomials -- 12.1.1 B´ezier curves and the de Casteljau algorithm -- 12.1.2 Continuity of piecewise curves -- 12.2 The polar form of B-splines -- 12.2.1 Knot vectors and control points -- 12.2.2 Knot insertion and the de Boor algorithm -- 12.2.3 B´ezier decomposition and function subdivision -- Note -- 13 State-of-the-Art and Future Directions -- 13.1 State-of-the-art -- 13.2 Future directions -- Appendix A: Connectivity Arrays -- A.1 The INC Array -- A.2 The IEN array -- A.3 The ID array -- A.3.1 The scalar case -- A.3.2 The vector case -- A.4 The LM array -- Note -- References -- Index. 7.3 Nonlinear time integration: The generalized-$\alpha$ method -- Note -- 8 Nearly Incompressible Solids -- 8.1 formulation for linear elasticity using NURBS -- 8.1.1 An intuitive look at mesh locking -- 8.1.2 Strain projection and the method -- 8.1.3 , the projection operator, and NURBS -- 8.1.4 Infinite plate with circular hole under in-plane tension -- 8.2 formulation for nonlinear elasticity -- 8.2.1 Constitutive equations -- 8.2.2 Pinched torus -- Notes -- 9 Fluids -- 9.1 Dispersion analysis -- 9.1.1 Pure advection: the first-order wave equation -- 9.1.2 Pure diffusion: the heat equation -- 9.2 The variational multiscale (VMS) method -- 9.2.1 Numerical example: linear advection-diffusion -- 9.2.2 The Green's operator -- 9.2.3 A multiscale decomposition -- 9.2.4 The variational multiscale formulation -- 9.2.5 Reconciling Galerkin's method with VMS -- 9.3 Advection-diffusion equation -- 9.3.1 Formulating the problem -- 9.3.2 The streamline upwind/Petrov-Galerkin (SUPG) method -- 9.3.3 Numerical example: advection-diffusion in two dimensions, revisited -- 9.4 Turbulence -- 9.4.1 Incompressible Navier-Stokes equations -- 9.4.2 Multiscale residual-based formulation of the incompressible Navier-Stokes equations employing the advective form -- 9.4.3 Turbulent channel flow -- Notes -- 10 Fluid-Structure Interaction and Fluids on Moving Domains -- 10.1 The arbitrary Lagrangian-Eulerian (ALE) formulation -- 10.2 Inflation of a balloon -- 10.3 Flow in a patient-specific abdominal aorta with aneurysm -- 10.3.1 Construction of the arterial cross-section -- 10.3.2 Numerical results -- 10.4 Rotating components -- 10.4.1 Coupling of the rotating and stationary domains -- 10.4.2 Numerical example: two propellers spinning in opposite directions -- Appendix 10.A: A geometrical template for arterial blood flow modeling -- 11 Higher-order Partial Differential Equations.},
author = {Cottrell, J. Austin. and Hughes, Thomas J. R. and Bazilevs, Yuri.},
doi = {10.1002/9780470749081.ch7},
pages = {335},
publisher = {Wiley},
title = {{Isogeometric analysis: toward integration of CAD and FEA}},
year = {2009}
}
@article{DePrenter2017,
abstract = {The (Isogeometric) Finite Cell Method–in which a domain is immersed in a structured background mesh–suffers from conditioning problems when cells with small volume fractions occur. In this contribution, we establish a rigorous scaling relation between the condition number of (I)FCM system matrices and the smallest cell volume fraction. Ill-conditioning stems either from basis functions being small on cells with small volume fractions, or from basis functions being nearly linearly dependent on such cells. Based on these two sources of ill-conditioning, an algebraic preconditioning technique is developed, which is referred to as Symmetric Incomplete Permuted Inverse Cholesky (SIPIC). A detailed numerical investigation of the effectivity of the SIPIC preconditioner in improving (I)FCM condition numbers and in improving the convergence speed and accuracy of iterative solvers is presented for the Poisson problem and for two- and three-dimensional problems in linear elasticity, in which Nitche's method is applied in either the normal or tangential direction. The accuracy of the preconditioned iterative solver enables mesh convergence studies of the finite cell method.},
archivePrefix = {arXiv},
arxivId = {1601.05129},
author = {de Prenter, F. and Verhoosel, C. V. and van Zwieten, G. J. and van Brummelen, E. H.},
doi = {10.1016/j.cma.2016.07.006},
eprint = {1601.05129},
issn = {00457825},
journal = {Computer Methods in Applied Mechanics and Engineering},
keywords = {Condition number,Finite Cell Method,Immersed/fictitious domain methods,Isogeometric Analysis,Iterative solvers,Preconditioning},
month = {apr},
pages = {297--327},
publisher = {North-Holland},
title = {{Condition number analysis and preconditioning of the finite cell method}},
url = {https://www.sciencedirect.com/science/article/pii/S0045782516307277},
volume = {316},
year = {2017}
}
@article{elman_2008,
abstract = {In recent years, considerable effort has been placed on developing efficient and robust solution algorithms for the incompressible Navier-Stokes equations based on preconditioned Krylov methods. These include physics-based methods, such as SIMPLE, and purely algebraic preconditioners based on the approximation of the Schur complement. All these techniques can be represented as approximate block factorization (ABF) type preconditioners. The goal is to decompose the application of the preconditioner into simplified sub-systems in which scalable multi-level type solvers can be applied. In this paper we develop a taxonomy of these ideas based on an adaptation of a generalized approximate factorization of the Navier-Stokes system first presented in [A. Quarteroni, F. Saleri, A. Veneziani, Factorization methods for the numerical approximation of Navier-Stokes equations, Computational Methods in Applied Mechanical Engineering 188 (2000) 505-526]. This taxonomy illuminates the similarities and differences among these preconditioners and the central role played by efficient approximation of certain Schur complement operators. We then present a parallel computational study that examines the performance of these methods and compares them to an additive Schwarz domain decomposition (DD) algorithm. Results are presented for two and three-dimensional steady state problems for enclosed domains and inflow/outflow systems on both structured and unstructured meshes. The numerical experiments are performed using MPSalsa, a stabilized finite element code. {\textcopyright} 2007 Elsevier Inc. All rights reserved.},
author = {Elman, Howard and Howle, V. E. and Shadid, John and Shuttleworth, Robert and Tuminaro, Ray},
doi = {10.1016/j.jcp.2007.09.026},
isbn = {0021-9991},
issn = {00219991},
journal = {Journal of Computational Physics},
keywords = {Incompressible flow,Iterative methods,Navier-Stokes},
month = {jan},
number = {3},
pages = {1790--1808},
publisher = {Academic Press},
title = {{A taxonomy and comparison of parallel block multi-level preconditioners for the incompressible Navier-Stokes equations}},
url = {https://www.sciencedirect.com/science/article/pii/S0021999107004330},
volume = {227},
year = {2008}
}
@article{fang_2018,
abstract = {Copyright {\textcopyright} 2018 John Wiley {\&} Sons, Ltd. This work introduces a novel, mortar-based coupling scheme for electrode-electrolyte interfaces in 3-dimensional finite element models for lithium-ion cells and similar electrochemical systems. The coupling scheme incorporates the widely applied Butler-Volmer charge transfer kinetics, but conceptually also works for other interface equations. Unlike conventional approaches, the coupling scheme allows flexible mesh generation for the electrode and electrolyte phases with nonmatching meshes at electrode-electrolyte interfaces. As a result, the desired spatial mesh resolution in each phase and the resulting computational effort can be easily controlled, leading to improved efficiency. All governing equations are solved in a monolithic fashion as a holistic, unified system of linear equations for computational robustness and performance reasons. Consistency and optimal convergence behavior of the coupling scheme are demonstrated in elementary numerical tests, and the discharge of two different realistic lithium-ion cells, each consisting of an anode, a cathode, and an electrolyte, is also simulated. One of the two cells involves about 1.35 million degrees of freedom and very complex microstructural geometries obtained from X-ray tomography data. For validation purposes, characteristic numerical results from the literature are reproduced, and the coupling scheme is shown to require considerably fewer degrees of freedom than a standard discretization with matching interface meshes to achieve a similar level of accuracy.},
author = {Fang, Rui and Farah, Philipp and Popp, Alexander and Wall, Wolfgang A.},
doi = {10.1002/nme.5792},
issn = {10970207},
journal = {International Journal for Numerical Methods in Engineering},
keywords = {Butler-Volmer kinetics,coupled electrochemical simulation,electrode-electrolyte interface,monolithic coupling,mortar-based finite element method},
month = {jun},
number = {13},
pages = {1411--1437},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{A monolithic, mortar-based interface coupling and solution scheme for finite element simulations of lithium-ion cells}},
url = {http://doi.wiley.com/10.1002/nme.5792},
volume = {114},
year = {2018}
}
@article{felippa_2001,
abstract = {This is a tutorial article that reviews the use of partitioned analysis procedures for the analysis of coupled dynamical systems. Attention is focused on the computational simulation of systems in which a structure is a major component. Important applications in that class are provided by thermomechanics, fluid-structure interaction and control-structure interaction. In the partitioned solution approach, systems are spatially decomposed into partitions. This decomposition is driven by physical or computational considerations. The solution is separately advanced in time over each partition. Interaction effects are accounted for by transmission and synchronization of coupled state variables. Recent developments in the use of this approach for multilevel decomposition aimed at massively parallel computation are discussed. {\textcopyright} 2001 Elsevier Science B.V. All rights reserve.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Felippa, Carlos A. and Park, K. C. and Farhat, Charbel},
doi = {10.1016/S0045-7825(00)00391-1},
eprint = {arXiv:1011.1669v3},
isbn = {0045-7825},
issn = {00457825},
journal = {Computer Methods in Applied Mechanics and Engineering},
keywords = {Coupled systems,Fluid-structure interaction,Multiphysics,Parallel computation,Partitioned analysis,Staggered solution},
month = {mar},
number = {24-25},
pages = {3247--3270},
pmid = {25246403},
publisher = {North-Holland},
title = {{Partitioned analysis of coupled mechanical systems}},
url = {https://www.sciencedirect.com/science/article/pii/S0045782500003911?via{\%}3Dihub},
volume = {190},
year = {2001}
}
@article{forster_2007,
abstract = {Within this paper the so-called artificial added mass effect is investigated which is responsible for devastating instabilities within sequentially staggered Fluid-structure Interaction (FSI) simulations where incompressible fluids are considered. A discrete representation of the added mass operator MAis given and 'instability conditions' are evaluated for different temporal discretisation schemes. It is proven that for every sequentially staggered scheme and given spatial discretisation of a problem, a mass ratio between fluid and structural mass density can be found at which the coupled system becomes unstable. The analysis is quite general and does not depend upon the particular spatial discretisation schemes used. However here special attention is given to stabilised finite elements employed on the fluid partition. Numerical investigations further highlight the results. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {F{\"{o}}rster, Christiane and Wall, Wolfgang A. and Ramm, Ekkehard},
doi = {10.1016/j.cma.2006.09.002},
isbn = {0045-7825},
issn = {00457825},
journal = {Computer Methods in Applied Mechanics and Engineering},
keywords = {Artificial added mass,Fluid-structure interaction,Partitioned procedure,Stability},
month = {jan},
number = {7},
pages = {1278--1293},
pmid = {17895595},
publisher = {North-Holland},
title = {{Artificial added mass instabilities in sequential staggered coupling of nonlinear structures and incompressible viscous flows}},
url = {https://www.sciencedirect.com/science/article/pii/S0045782506002544?via{\%}3Dihub},
volume = {196},
year = {2007}
}
@article{gee_2011,
abstract = {The coupling of flexible structures to incompressible fluids draws a lot of attention during the last decade. Many different solution schemes have been proposed. In this contribution, we concentrate on the strong coupling fluid–structure interaction by means of monolithic solution schemes. Therein, a Newton–Krylov method is applied to the monolithic set of nonlinear equations. Such schemes require good preconditioning to be efficient. We propose two preconditioners that apply algebraic multigrid techniques to the entire fluid–structure interaction system of equations. The first is based on a standard block Gauss–Seidel approach, where approximate inverses of the individual field blocks are based on a algebraic multigrid hierarchy tailored for the type of the underlying physical problem. The second is based on a monolithic coarsening scheme for the coupled system that makes use of prolongation and restriction projections constructed for the individual fields. The resulting nonsymmetric monolithic algebraic multigrid method therefore involves coupling of the fields on coarse approximations to the problem yielding significantly enhanced performance.},
archivePrefix = {arXiv},
arxivId = {1010.1724},
author = {Gee, M. W. and K{\"{u}}ttler, U. and Wall, W. A.},
doi = {10.1002/nme.3001},
eprint = {1010.1724},
isbn = {978-1-4577-0079-8},
issn = {00295981},
journal = {International Journal for Numerical Methods in Engineering},
keywords = {Algebraic multigrid,Fluid-structure interaction,Monolithic solution schemes},
month = {feb},
number = {8},
pages = {987--1016},
pmid = {260949200001},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Truly monolithic algebraic multigrid for fluid-structure interaction}},
url = {http://doi.wiley.com/10.1002/nme.3001},
volume = {85},
year = {2011}
}
@article{Griewank2000,
abstract = {In its basic form, the reverse mode of computational differentiation yields the gradient of a scalar-valued function at a cost that is a small multiple of the computational work needed to evaluate the function itself. However, the corresponding memory requirement is proportional to the run-time of the evaluation program. Therefore, the practical applicability of the reverse mode in its original formulation is limited despite the availability of ever larger memory systems. This observation leads to the development of checkpointing schedules to reduce the storage requirements. This article presents the function tt revolve, which generates checkpointing schedules that are provably optimal with regard to a primary and a secondary criterion. This routine is intended to be used as an explicit ``controller'' for running a time-dependent applications program.},
author = {Griewank, Andreas and Walther, Andrea},
doi = {10.1145/347837.347846},
issn = {00983500},
journal = {ACM Transactions on Mathematical Software},
keywords = {adjoint mode,checkpointing,computational differentiation,reverse mode},
month = {mar},
number = {1},
pages = {19--45},
publisher = {ACM},
title = {{Algorithm 799: revolve: an implementation of checkpointing for the reverse or adjoint mode of computational differentiation}},
url = {http://portal.acm.org/citation.cfm?doid=347837.347846},
volume = {26},
year = {2000}
}
@article{Heroux2005,
abstract = {The Trilinos Project is an effort to facilitate the design, development, integration and ongoing support of mathematical software libraries within an object-oriented framework for the solution of large-scale, complex multi-physics engineering and scienti c problems. Trilinos addresses two fundamental issues of developing software for these problems: (i) Providing a streamlined process and set of tools for development of new algorithmic implementations and (ii) promoting interoperability of independently developed software. par Trilinos uses a two-level software structure designed around collections of packages. A Trilinos package is an integral unit usually developed by a small team of experts in a particular algorithms area such as algebraic preconditioners, nonlinear solvers, etc. Packages exist underneath the Trilinos top level, which provides a common look-and-feel, including configuration, documentation, licensing, and bug-tracking. par Here we present the overall Trilinos design, describing our use of abstract interfaces and default concrete implementations. We discuss the services that Trilinos provides to a prospective package and how these services are used by various packages. We also illustrate how packages can be combined to rapidly develop new algorithms. Finally, we discuss how Trilinos facilitates highquality software engineering practices that are increasingly required from simulation software.},
author = {Heroux, Michael A. and Phipps, Eric T. and Salinger, Andrew G. and Thornquist, Heidi K. and Tuminaro, Ray S. and Willenbring, James M. and Williams, Alan and Stanley, Kendall S. and Bartlett, Roscoe A. and Howle, Vicki E. and Hoekstra, Robert J. and Hu, Jonathan J. and Kolda, Tamara G. and Lehoucq, Richard B. and Long, Kevin R. and Pawlowski, Roger P.},
doi = {10.1145/1089014.1089021},
isbn = {0098-3500},
issn = {00983500},
journal = {ACM Transactions on Mathematical Software},
keywords = {Software Quality Engineering,Software framework,interfaces},
month = {sep},
number = {3},
pages = {397--423},
pmid = {2258803},
publisher = {ACM},
title = {{An overview of the Trilinos project}},
url = {http://portal.acm.org/citation.cfm?doid=1089014.1089021},
volume = {31},
year = {2005}
}
@article{hiriyur_quasi-algebraic_2012,
abstract = {The modeling of discontinuities arising from fracture of materials poses a number of significant computational challenges. The extended finite element method provides an attractive alternative to standard finite elements in that they do not require fine spatial resolution in the vicinity of discontinuities nor do they require repeated remeshing to properly address propagation of cracks. They do, however, give rise to linear systems requiring special care within an iterative solver method. An algebraic multigrid method is proposed that is suitable for the linear systems associated with modeling fracture via extended finite elements. The new method follows naturally from an energy minimizing algebraic multigrid framework. The key idea is the modification of the prolongator sparsity pattern to prevent interpolation across cracks. This is accomplished by accessing the standard levelset functions used during the discretization process. Numerical experiments illustrate that the resulting method converges in a fashion that is relatively insensitive to mesh resolution and to the number of cracks or their location.},
author = {Hiriyur, B and Tuminaro, R and Waisman, H and Boman, E and Keyes, D},
doi = {10.1137/110819913},
issn = {1064-8275},
journal = {SIAM Journal on Scientific Computing},
keywords = {X-FEM,multigrid,preconditioner},
month = {jan},
number = {2},
pages = {A603----A626},
title = {{A Quasi-algebraic Multigrid Approach to Fracture Problems Based on Extended Finite Elements}},
volume = {34},
year = {2012}
}
@article{Kirby2006,
abstract = {As a key step towards a complete automation of the finite element method, we present a new algorithm for automatic and efficient evaluation of multilinear variational forms. The algorithm has been implemented in the form of a compiler, the FEniCS Form Compiler (FFC). We present benchmark results for a series of standard variational forms, including the incompressible Navier-Stokes equations and linear elasticity. The speedup compared to the standard quadrature-based approach is impressive; in some cases the speedup is as large as a factor of 1000. {\textcopyright} 2006 ACM.},
archivePrefix = {arXiv},
arxivId = {1112.0402},
author = {Kirby, Robert C and Logg, Anders},
doi = {10.1145/1163641.1163644},
eprint = {1112.0402},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kirby - Unknown - A Compiler for Variational Forms.pdf:pdf},
issn = {00983500},
journal = {ACM Transactions on Mathematical Software},
keywords = {Automation,Compiler,Finite element,Variational form},
number = {3},
pages = {417--444},
title = {{A compiler for variational forms}},
volume = {32},
year = {2006}
}
@article{kremheller_2018,
abstract = {We present a dynamic vascular tumor model combining a multiphase porous medium framework for avascular tumor growth in a consistent Arbitrary Lagrangian Eulerian formulation and a novel approach to incorporate angiogenesis. The multiphase model is based on Thermodynamically Constrained Averaging Theory and comprises the extracellular matrix as a porous solid phase and three fluid phases: (living and necrotic) tumor cells, host cells and the interstitial fluid. Angiogenesis is modeled by treating the neovasculature as a proper additional phase with volume fraction or blood vessel density. This allows us to define consistent inter-phase exchange terms between the neovasculature and the interstitial fluid. As a consequence, transcapillary leakage and lymphatic drainage can be modeled. By including these important processes we are able to reproduce the increased interstitial pressure in tumors which is a crucial factor in drug delivery and, thus, therapeutic outcome. Different coupling schemes to solve the resulting five-phase problem are realized and compared with respect to robustness and computational efficiency. We find that a fully monolithic approach is superior to both the standard partitioned and a hybrid monolithic-partitioned scheme for a wide range of parameters. The flexible implementation of the novel model makes further extensions (e.g., inclusion of additional phases and species) straightforward.},
author = {Kremheller, Johannes and Vuong, Anh Tu and Yoshihara, Lena and Wall, Wolfgang A. and Schrefler, Bernhard A.},
doi = {10.1016/j.cma.2018.06.009},
issn = {00457825},
journal = {Computer Methods in Applied Mechanics and Engineering},
keywords = {Angiogenesis,Monolithic coupling,Multiphase flow,Porous media,Tumor growth},
month = {oct},
pages = {657--683},
publisher = {North-Holland},
title = {{A monolithic multiphase porous medium framework for (a-)vascular tumor growth}},
url = {https://www.sciencedirect.com/science/article/pii/S0045782518303074},
volume = {340},
year = {2018}
}
@article{Lehrenfeld2015,
abstract = {We investigated Ricciardelli et al.'s (2002) claim, that the tendency for gaze direction to elicit automatic attentional following is unique to biologically significant information. Participants made voluntary saccades to targets on the left or the right of a display, which were either congruent or incongruent with a centrally presented distractor (eye-gaze or arrow). Contrary to Ricciardelli et al., for both distractor types, saccade latencies were slower, and participants made more directional errors, on incongruent than on congruent trials. Moreover, a cost-benefit analysis showed no difference between the two distractor types. However, latencies for erroneous saccades were faster than correctly directed saccades for the eye-gaze distractors, but not for the arrow distractors},
archivePrefix = {arXiv},
arxivId = {1408.2941v1},
author = {Lehrenfeld, Christoph},
doi = {10.1137/130943534},
eprint = {1408.2941v1},
issn = {1064-8275},
journal = {SIAM Journal on Scientific Computing},
keywords = {4D quadrature,65D30,65M30,XFEM,computations,discontinuous Galerkin,evolving surface,finite elements,parabolic PDE,space-time,two-phase flow},
month = {jan},
number = {1},
pages = {A245--A270},
publisher = {Society for Industrial and Applied Mathematics},
title = {{The Nitsche XFEM-DG Space-Time Method and its Implementation in Three Space Dimensions}},
url = {http://epubs.siam.org/doi/10.1137/130943534 http://epubs.siam.org/doi/abs/10.1137/130943534},
volume = {37},
year = {2015}
}
@article{tobin_2001,
author = {{Martin J}, Tobin},
doi = {10.1056/NEJM200106283442606},
issn = {0028-4793},
journal = {The New England Journal of Medicine},
month = {jun},
number = {26},
pages = {1986--1996},
pmid = {11430329},
title = {{Advances in mechanical ventilation}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11430329 http://www.nejm.org/doi/abs/10.1056/NEJM200106283442606},
volume = {344},
year = {2001}
}
@article{menk_robust_2011,
abstract = {The extended finite element method enhances the approximation properties of the finite element space by using additional enrichment functions. But the resulting stiffness matrices can become ill-conditioned. In that case iterative solvers need a large number of iterations to obtain an acceptable solution. In this paper a procedure is described to obtain stiffness matrices whose condition number is close to the one of the finite element matrices without any enrichments. A domain decomposition is employed and the algorithm is very well suited for parallel computations. The method was tested in numerical experiments to show its effectiveness. The experiments have been conducted for structures containing cracks and material interfaces. We show that the corresponding enrichments can result in arbitrarily ill-conditioned matrices. The method proposed here, however, provides well-conditioned matrices and can be applied to any sort of enrichment. The complexity of this approach and its relation to the domain decomposition is discussed. Computation times have been measured for a structure containing multiple cracks. For this structure the computation times could be decreased by a factor of 2. Copyright {\textcopyright} 2010 John Wiley {\&} Sons, Ltd.},
author = {Menk, Alexander and Bordas, St{\'{e}}phane P A},
doi = {10.1002/nme.3032},
issn = {1097-0207},
journal = {International Journal for Numerical Methods in Engineering},
keywords = {Condition number,X-FEM,cracks,domain decomposition,iterative solvers,material interfaces,preconditioner},
month = {apr},
number = {13},
pages = {1609--1632},
title = {{A robust preconditioning technique for the extended finite element method}},
volume = {85},
year = {2011}
}
@book{saad_iterative_2003,
author = {Saad, Yousef},
edition = {2},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saad - 2003 - Iterative Methods for Sparse Linear Systems, Second Edition.pdf:pdf},
isbn = {0-89871-534-2},
month = {apr},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Iterative Methods for Sparse Linear Systems, Second Edition}},
year = {2003}
}
@article{Schillinger2015,
abstract = {The finite cell method is an embedded domain method, which combines the fictitious domain approach with higher-order finite elements, adaptive integration, and weak enforcement of unfitted essential boundary conditions. Its core idea is to use a simple unfitted structured mesh of higher-order basis functions for the approximation of the solution fields, while the geometry is captured by means of adaptive quadrature points. This eliminates the need for boundary conforming meshes that require time-consuming and error-prone mesh generation procedures, and opens the door for a seamless integration of very complex geometric models into finite element analysis. At the same time, the finite cell method achieves full accuracy, i.e. optimal rates of convergence, when the mesh is refined, and exponential rates of convergence, when the polynomial degree is increased. Due to the flexibility of the quadrature based geometry approximation, the finite cell method can operate with almost any geometric model, ranging from boundary representations in computer aided geometric design to voxel representations obtained from medical imaging technologies. In this review article, we first provide a concise introduction to the basics of the finite cell method. We then summarize recent developments of the technology, with particular emphasis on the research topics in which we have been actively involved. These include the finite cell method with B-spline and NURBS basis functions, the treatment of geometric nonlinearities for large deformation analysis, the weak enforcement of boundary and coupling conditions, and local refinement schemes. We illustrate the capabilities and advantages of the finite cell method with several challenging examples, e.g. the image-based analysis of foam-like structures, the patient-specific analysis of a human femur bone, the analysis of volumetric structures based on CAD boundary representations, and the isogeometric treatment of trimmed NURBS surfaces. We conclude our review by briefly discussing some key aspects for the efficient implementation of the finite cell method.},
author = {Schillinger, Dominik and Ruess, Martin},
doi = {10.1007/s11831-014-9115-y},
isbn = {1134-3060},
issn = {18861784},
journal = {Archives of Computational Methods in Engineering},
month = {jul},
number = {3},
pages = {391--455},
publisher = {Springer Netherlands},
title = {{The Finite Cell Method: A Review in the Context of Higher-Order Structural Analysis of CAD and Image-Based Geometric Models}},
volume = {22},
year = {2015}
}
@book{toselli_2005,
abstract = {The purpose of this text is to offer a comprehensive and self-contained presentation of some of the most successful and popular domain decomposition preconditioners for finite and spectral element approximations of partial differential equations. Strong emphasis is placed on both algorithmic and mathematical aspects. Some important methods such FETI and balancing Neumann- Neumann methods and algorithms for spectral element methods, not treated previously in any monograph, are covered in detail. Winner of the 2005 Award for Excellence in Professional and Scholarly Publishing - Mathematics/Statistics - of the Association of American Publishers},
address = {Berlin, Heidelberg},
author = {Toselli, Andrea and Widlund, Olof B.},
doi = {10.1007/b137868},
isbn = {978-3-540-20696-5},
issn = {0179-3632},
publisher = {Springer Berlin Heidelberg},
series = {Springer Series in Computational Mathematics},
title = {{Domain Decomposition Methods — Algorithms and Theory}},
url = {http://link.springer.com/10.1007/b137868},
volume = {34},
year = {2005}
}
@article{verdugo_2016b,
abstract = {We present efficient preconditioners for one of the most physiologically relevant pulmonary models currently available. Our underlying motivation is to enable the efficient simulation of such a lung model on high-performance computing platforms in order to assess mechanical ventilation strategies and contributing to design more protective patient-specific ventilation treatments. The system of linear equations to be solved using the proposed preconditioners is essentially the monolithic system arising in fluid–structure interaction (FSI) extended by additional algebraic constraints. The introduction of these constraints leads to a saddle point problem that cannot be solved with usual FSI preconditioners available in the literature. The key ingredient in this work is to use the idea of the semi-implicit method for pressure-linked equations (SIMPLE) for getting rid of the saddle point structure, resulting in a standard FSI problem that can be treated with available techniques. The numerical examples show that the resulting preconditioners approach the optimal performance of multigrid methods, even though the lung model is a complex multiphysics problem. Moreover, the preconditioners are robust enough to deal with physiologically relevant simulations involving complex real-world patient-specific lung geometries. The same approach is applicable to other challenging biomedical applications where coupling between flow and tissue deformations is modeled with additional algebraic constraints. Copyright {\textcopyright}2016 John Wiley {\$}\backslash{\$}{\&} Sons, Ltd.},
author = {Verdugo, F and Roth, C J and Yoshihara, L and Wall, W A},
doi = {10.1002/cnm.2795},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Verdugo et al. - 2016 - Efficient solvers for coupled models in respiratory mechanics.pdf:pdf},
issn = {2040-7947},
journal = {International Journal for Numerical Methods in Biomedical Engineering},
keywords = {Q1,algebraic multigrid,block preconditioners,coupled problems,high-performance computing,respiratory mechanics},
mendeley-tags = {Q1},
month = {jan},
title = {{Efficient solvers for coupled models in respiratory mechanics}},
url = {http://onlinelibrary.wiley.com.recursos.biblioteca.upc.edu/doi/10.1002/cnm.2795/abstract},
year = {2016}
}
@article{verdugo_2013,
abstract = {This article presents a new approach to assess the error in specific$\backslash$nquantities of interest in the framework of linear elastodynamics. In$\backslash$nparticular, a new type of quantities of interest (referred as$\backslash$ntimeline-dependent quantities) is proposed. These quantities are scalar$\backslash$ntime-dependent outputs of the transient solution, which are better$\backslash$nsuited to time-dependent problems than the standard scalar ones, frozen$\backslash$nin time. The proposed methodology furnishes error estimates for both the$\backslash$nstandard scalar and the new timeline-dependent quantities of interest.$\backslash$nThe key ingredient is the modal-based approximation of the associated$\backslash$nadjoint problems, which allows efficiently computing and storing the$\backslash$nadjoint solution.$\backslash$nThe approximated adjoint solution is readily post-processed to produce$\backslash$nan enhanced solution, requiring only one spatial post-process for each$\backslash$nvibration mode and using the time-harmonic hypothesis to recover the$\backslash$ntime dependence. Thus, the proposed goal-oriented error estimate$\backslash$nconsists in injecting this enhanced adjoint solution into the residual$\backslash$nof the direct problem. The resulting estimate is very well suited for$\backslash$ntransient dynamic simulations because the enhanced adjoint solution is$\backslash$ncomputed before starting the forward time integration of the direct$\backslash$nproblem. Thus, the cost of the error estimate at each time step is very$\backslash$nlow. Copyright (C) 2013 John Wiley {\&} Sons, Ltd.},
author = {Verdugo, F. and Par{\'{e}}s, N. and D{\'{i}}ez, P.},
doi = {10.1002/nme.4538},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Verdugo, Par{\'{e}}s, D{\'{i}}ez - 2013 - Modal-based goal-oriented error assessment for timeline-dependent quantities in transient dynamics.pdf:pdf},
issn = {00295981},
journal = {Int. J. Numer. Meth. Engng.},
keywords = {Adjoint problem,Elastodynamics,Goal-oriented error assessment,Modal analysis,Q1,Quantity of interest,Timeline-dependent quantity of interest,Transient dynamics},
mendeley-tags = {Q1},
number = {8},
pages = {685--720},
title = {{Modal-based goal-oriented error assessment for timeline-dependent quantities in transient dynamics}},
volume = {95},
year = {2013}
}
@article{Verdugo2019a,
author = {Verdugo, Francesc and Badia, Santiago},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Verdugo, Badia - 2019 - A user-guide to Gridap -- grid-based approximation of partial differential equations in Julia.pdf:pdf},
journal = {Arxiv preprints},
title = {{A user-guide to Gridap -- grid-based approximation of partial differential equations in Julia}},
year = {2019}
}
@article{verdugo_2012,
abstract = {This work presents a new technique yielding computable bounds of quantities of interest in the framework of linear visco-elastodynamics. A novel expression for the error representation is introduced, alternative to the previous ones using the Cauchy-Schwarz inequality. The proposed formulation utilizes symmetrized forms of the error equations to derive error bounds in terms of energy error measures. The practical implementation of the method is based on constructing admissible fields for both the original problem and the adjoint problem associated with the quantity of interest. Here, the flux-free technique is considered to compute the admissible stress fields. The proposed methodology yields estimates with better quality than the ones based on the Cauchy-Schwarz inequality. In the studied examples the bound gaps obtained are approximately halved, that is the estimated intervals of confidence are reduced. {\textcopyright} 2012 Elsevier B.V..},
author = {Verdugo, Francesc and D{\'{i}}ez, Pedro},
doi = {10.1016/j.cma.2012.06.016},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Verdugo, D{\'{i}}ez - 2012 - Computable bounds of functional outputs in linear visco-elastodynamics.pdf:pdf},
isbn = {9783950353709},
issn = {0045-7825},
journal = {Computer Methods in Applied Mechanics and Engineering},
keywords = {Adjoint problem,Computable bounds,Goal-oriented error assessment,Q1,Quantity of interest,Visco-elastodynamics},
mendeley-tags = {Q1},
month = {oct},
pages = {313--330},
title = {{Computable bounds of functional outputs in linear visco-elastodynamics}},
url = {http://www.sciencedirect.com/science/article/pii/S0045782512002046},
volume = {245–246},
year = {2012}
}
@article{verdugo_2019,
abstract = {The aggregated unfitted finite element method (AgFEM) is a methodology recently introduced in order to address conditioning and stability problems associated with embedded, unfitted, or extended finite element methods. The method is based on removal of basis functions associated with badly cut cells by introducing carefully designed constraints, which results in well-posed systems of linear algebraic equations, while preserving the optimal approximation order of the underlying finite element spaces. The specific goal of this work is to present the implementation and performance of the method on distributed-memory platforms aiming at the efficient solution of large-scale problems. In particular, we show that, by considering AgFEM, the resulting systems of linear algebraic equations can be effectively solved using standard algebraic multigrid preconditioners. This is in contrast with previous works that consider highly customized preconditioners in order to allow one the usage of iterative solvers in combination with unfitted techniques. Another novelty with respect to the methods available in the literature is the problem sizes that can be handled with the proposed approach. While most of previous references discussing linear solvers for unfitted methods are based on serial non-scalable algorithms, we propose a parallel distributed-memory method able to efficiently solve problems at large scales. This is demonstrated by means of a weak scaling test defined on complex 3D domains up to 300M degrees of freedom and one billion cells on 16K CPU cores in the Marenostrum-IV platform. The parallel implementation of the AgFEM method is available in the large-scale finite element package FEMPAR.},
archivePrefix = {arXiv},
arxivId = {1902.01168},
author = {Verdugo, Francesc and Mart{\'{i}}n, Alberto F. and Badia, Santiago},
doi = {10.1016/j.cma.2019.112583},
eprint = {1902.01168},
issn = {00457825},
journal = {Computer Methods in Applied Mechanics and Engineering},
keywords = {Algebraic multigrid,High performance scientific computing,Unfitted finite element methods},
month = {dec},
pages = {112583},
title = {{Distributed-memory parallelization of the aggregated unfitted finite element method}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782519304542},
volume = {357},
year = {2019}
}
@article{verdugo_error_2014,
abstract = {This paper presents in a unified framework the most representative state-of-the-art techniques on a posteriori error assessment for second order hyperbolic problems, i.e., structural transient dynamics. For the sake of presentation, the error estimates are grouped in four types: recovery-based estimates, the dual weighted residual method, the constitutive relation error method and error estimates for timeline-dependent quantities of interest. All these methodologies give a comprehensive overview on the available error assessment techniques in structural dynamics, both for energy-like and goal-oriented estimates.},
author = {Verdugo, Francesc and Par{\'{e}}s, N{\'{u}}ria and D{\'{i}}ez, Pedro},
doi = {10.1007/s11831-014-9096-x},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Verdugo, Par{\'{e}}s, D{\'{i}}ez - 2014 - Error Assessment in Structural Transient Dynamics.pdf:pdf},
issn = {1134-3060, 1886-1784},
journal = {Archives of Computational Methods in Engineering},
keywords = {Adjoint problem,Appl.Mathematics/Computational Methods of Enginee,Constitutive relation error,Dual weighted residuals,Elastodynamics,Goal-oriented error assessment,Q1,Quantity of interest,Recovery estimates,Timeline-dependent quantity of interest,Transient dynamics},
mendeley-tags = {Q1},
month = {jan},
number = {1},
pages = {59--90},
title = {{Error Assessment in Structural Transient Dynamics}},
url = {http://link.springer.com/article/10.1007/s11831-014-9096-x},
volume = {21},
year = {2014}
}
@article{verdugo_2014a,
abstract = {This article presents a space-time adaptive strat-egy for transient elastodynamics. The method aims at com-puting an optimal space-time discretization such that the computed solution has an error in the quantity of interest below a user-defined tolerance. The methodology is based on a goal-oriented error estimate that requires accounting for an auxiliary adjoint problem. The major novelty of this paper is using modal analysis to obtain a proper approx-imation of the adjoint solution. The idea of using a modal-based description was introduced in a previous work for error estimation purposes. Here this approach is used for the first time in the context of adaptivity. With respect to the standard direct time-integration methods, the modal solution of the adjoint problem is highly competitive in terms of computa-tional effort and memory requirements. The performance of the proposed strategy is tested in two numerical examples. The two examples are selected to be representative of dif-ferent wave propagation phenomena, one being a 2D bulky continuum and the second a 2D domain representing a struc-tural frame.},
author = {Verdugo, Francesc and Par{\'{e}}s, N{\'{u}}ria and D{\'{i}}ez, Pedro},
doi = {10.1007/s00466-014-0988-2},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Verdugo, Par{\'{e}}s, D{\'{i}}ez - 2014 - Goal-oriented space-time adaptivity for transient dynamics using a modal description of the adjoint solu.pdf:pdf},
isbn = {2},
issn = {01787675},
journal = {Comput. Mech.},
keywords = {Adaptivity,Adjoint problem,Elastodynamics,Goal-oriented error assessment,Modal analysis,Q1,Quantity of interest},
mendeley-tags = {Q1},
number = {2},
pages = {331--352},
title = {{Goal-oriented space-time adaptivity for transient dynamics using a modal description of the adjoint solution}},
volume = {54},
year = {2014}
}
@article{verdugo_2016,
abstract = {In this paper, we propose and evaluate the performance of a unified computational framework for preconditioning systems of linear equations resulting from the solution of coupled problems with monolithic schemes. The framework is composed by promising application-specific preconditioners presented previously in the literature with the common feature that they are able to be implemented for a generic coupled problem, involving an arbitrary number of fields, and to be used to solve a variety of applications. The first selected preconditioner is based on a generic block Gauss–Seidel iteration for uncoupling the fields, and standard algebraic multigrid (AMG) methods for solving the resulting uncoupled problems. The second preconditioner is based on the semi-implicit method for pressure-linked equations (SIMPLE) which is extended here to deal with an arbitrary number of fields, and also results in uncoupled problems that can be solved with standard AMG. Finally, a more sophisticated preconditioner is considered which enforces the coupling at all AMG levels, in contrast to the other two techniques which resolve the coupling only at the finest level. Our purpose is to show that these methods perform satisfactory in quite different scenarios apart from their original applications. To this end, we consider three very different coupled problems: thermo-structure interaction, fluid–structure interaction and a complex model of the human lung. Numerical results show that these general purpose methods are efficient and scalable in this range of applications.},
archivePrefix = {arXiv},
arxivId = {1605.01522},
author = {Verdugo, Francesc and Wall, Wolfgang A.},
doi = {10.1016/j.cma.2016.07.016},
eprint = {1605.01522},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Verdugo, Wall - 2016 - Unified computational framework for the efficient solution of n-field coupled problems with monolithic schemes.pdf:pdf},
issn = {0045-7825},
journal = {Computer Methods in Applied Mechanics and Engineering},
keywords = {Algebraic multigrid,Block preconditioners,Coupled problems,High performance computing,Monolithic solution schemes,Q1,algebraic multigrid,block preconditioners,coupled problems,monolithic solution schemes},
mendeley-tags = {Q1},
month = {oct},
pages = {335--366},
title = {{Unified computational framework for the efficient solution of n-field coupled problems with monolithic schemes}},
url = {http://www.sciencedirect.com/science/article/pii/S0045782516307575},
volume = {310},
year = {2016}
}
@techreport{Wall2014,
author = {Wall, W. A. and Gee, M. W.},
institution = {Technische Universit{\"{a}}t M{\"{u}}nchen},
title = {{BACI a multiphysics simulation environment}},
year = {2014}
}
@phdthesis{Holke2018,
abstract = {In this thesis, we develop, discuss and implement algorithms for scalable parallel tree-based adaptive mesh refinement (AMR) using space-filling curves (SFCs). We create an AMR software that works independently of the used element type, such as for example lines, triangles, tetrahedra, quadrilaterals, hexahedra, and prisms. Along with a detailed mathematical discussion, this requires the implementation as a numerical software and its validation, as well as scalability tests on current supercomputers. For triangular and tetrahedral elements (simplices) with red-refinement (1:4 in 2D, 1:8 in 3D), we develop a new SFC, the tetrahedral Morton space-filling curve (TM-SFC). Its construction is similar to the Morton index for quadrilaterals/hexahedra, as it is also based on bitwise interleaving the coordinates of a certain vertex of the simplex, the anchor node. Additionally, we interleave with a new piece of information, the so called type. The type distinguishes different simplices with the same anchor node. To store the necessary information of a d-dimensional simplex, we require 10 bytes per triangle and 14 bytes per tetrahedron, which is only one byte more than used in the classical Morton index for quadrilaterals (9 bytes) and hexahedra (13 bytes). For these simplices, we develop element local algorithms such as constructing the parent, children, or face-neighbors of a simplex, and show that most of them are constant-time operations independent of the refinement level. With SFC based partitioning it is possible that the mesh elements that are partitioned to one process do not form a face-connected domain. The amount of parallel communication among processes with neighboring domains rises with the number of face-connected components. We prove the following upper bounds for the number of face-connected components of segments of the TM-SFC: With a maximum refinement level of L, the number of face-connected components is bounded by 2(L − 1) in 2D and 2L + 1 in 3D. Additionally, we perform a numerical investigation of the distribution of lengths of SFC segments. Furthermore, we develop a new approach to partition and repartition a coarse (input) mesh among the processes. Compared to previous methods it optimizes for fine mesh load-balance and reduces the parallel communication of coarse mesh data. We discuss the coarse mesh repartitioning algorithm and demonstrate that our method repartitions a coarse mesh of 371e9 trees on 917,504 processes (405,000 trees per process) on the Juqueen supercomputer in 1.2 seconds. We develop an AMR concept that works independently of the element type; achieving this independence by strictly distinguishing between functions that operate on the whole mesh (high-level) and functions that locally operate on a single element or a small set of elements (low-level). We define an application programming interface (API) of low-level functions and develop the high-level functions such that every element-local operation is performed by a low-level function. Thus, by using different implementations of the low-level API for different meshes, or different parts of the same mesh, we are able to use different types of elements. Many numerical applications, for example finite element and finite volume solvers, require knowledge of a layer of ghost elements. Ghost elements of a process are those elements that lie on a different process but are (face-)neighbors of a process local element. We discuss a new approach to generate and manage these ghost elements that fits into our element-type independent approach. We define and describe the necessary low-level algorithms. Our main idea is the computation of tree-to-tree face-neighbors of an element via the explicit construction of the element's face as a lower dimensional element. In order to optimize the runtime of this method we enhance the algorithm with a top-down search method from Isaac, Burstedde, Wilcox, and Ghattas, and demonstrate how it speeds up the computation by factors of 10 to 20 achieving runtimes comparable to state-of-the art implementations with fixed element types. With the ghost algorithm we build a straight-forward ripple version of the 2:1 balance algorithm. This is not an optimized version but it serves as a feasibility study for our element-type independent approach. We implement all algorithms that we develop in this thesis in the new AMR library t8code, using the TM-SFC for simplicial and tetrahedral elements. Our modular approach allows us to reuse existing software, which we demonstrate by using the library p4est for quadrilateral and hexahedral elements. In a concurrent Bachelor's thesis by David Knapp (INS, Bonn) the necessary low-level algorithms for prisms were developed. With t8code we demonstrate that we can create, adapt, (re-)partition, and balance meshes, as well as create and manage a ghost layer. In various tests we show excellent strong and weak scaling behavior of our algorithms on up to 917,504 parallel processes on the Juqueen and Mira supercomputers using up to 858e9 mesh elements. We conclude this thesis by demonstrating how an application can be coupled with the AMR routines. We implement a finite volume based advection solver using t8code and show applications with triangular, quadrilateral, tetrahedral, and hexahedral elements, as well as 2D and 3D hybrid meshes, the latter consisting of tetrahedra, hexahedra, and prisms. Overall, we develop and demonstrate a new simplicial SFC and create a fast and scalable tree-based AMR software that offers a flexibility and generality that was previously not available. MSC Codes 65M50, 68W10, 65Y05, 65D18},
archivePrefix = {arXiv},
arxivId = {1803.04970},
author = {Holke, Johannes},
eprint = {1803.04970},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Holke - 2018 - Scalable Algorithms for Parallel Tree-based Adaptive Mesh Refinement with General Element Types.pdf:pdf},
issn = {23318422},
school = {Rheinische Friedrich-Wilhelms-Universit{\"{a}}t Bonn},
title = {{Scalable Algorithms for Parallel Tree-based Adaptive Mesh Refinement with General Element Types}},
url = {http://arxiv.org/abs/1803.04970},
year = {2018}
}
@article{Alnaes2015,
abstract = {The FEniCS Project is a collaborative project for the development of innovative concepts and tools for automated scientific computing, with a particular focus on the solution of differential equations by finite element methods. The FEniCS Projects software consists of a collection of interoperable software components, including DOLFIN, FFC, FIAT, Instant, UFC, UFL, and mshr. This note describes the new features and changes introduced in the release of FEniCS version 1.5.},
author = {Aln{\ae}s, Martin and Blechta, Jan and Hake, Johan and Johansson, August and Kehlet, Benjamin and Logg, Anders and Richardson, Chris and Ring, Johannes and Rognes, Marie E and Wells, Garth N},
doi = {10.11588/ans.2015.100.20553},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aln{\ae}s et al. - 2015 - The FEniCS Project Version 1.5.pdf:pdf},
issn = {2197-8263},
journal = {The FEniCS Project Version 1.5},
keywords = {Component-based software engineering,Computer science,Differential equation,Finite element method,Interoperability,Software,Software engineering},
month = {dec},
number = {100},
pages = {9--23},
title = {{The FEniCS Project Version 1.5}},
url = {https://journals.ub.uni-heidelberg.de/index.php/ans/article/view/20553},
volume = {3},
year = {2015}
}
@article{burman_2015,
author = {Burman, Erik and Claus, Susanne and Hansbo, P and Larson, M G and Massing, Andr{\'{e}}},
doi = {10.1002/nme.4823},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Burman et al. - 2015 - CutFEM Discretizing Geometry and Partial Differential Equations.pdf:pdf},
journal = {International Journal for Numerical Methods in Engineering},
keywords = {Extended finite element method,Finite element methods,Galerkin,Stability,level sets,meshfree methods,unfitted methods},
number = {7},
pages = {472--501},
title = {{CutFEM: Discretizing Geometry and Partial Differential Equations}},
volume = {104},
year = {2015}
}
@article{badia_2018b,
abstract = {In this work, we consider unfitted finite element methods for the numerical approximation of the Stokes problem. It is well-known that this kind of methods lead to arbitrarily ill-conditioned systems. In order to solve this issue, we consider the recently proposed aggregated finite element method, originally motivated for coercive problems. However, the well-posedness of the Stokes problem is far more subtle and relies on a discrete inf-sup condition. We consider mixed finite element methods that satisfy the discrete version of the inf-sup condition for body-fitted meshes, and analyze how the discrete inf-sup is affected when considering the unfitted case. We propose different aggregated mixed finite element spaces combined with simple stabilization terms, which can include pressure jumps and/or cell residuals, to fix the potential deficiencies of the aggregated inf-sup. We carry out a complete numerical analysis, which includes stability, optimal a priori error estimates, and condition number bounds that are not affected by the small cut cell problem. For the sake of conciseness, we have restricted the analysis to hexahedral meshes and discontinuous pressure spaces. A thorough numerical experimentation bears out the numerical analysis. The aggregated mixed finite element method is ultimately applied to two problems with non-trivial geometries.},
archivePrefix = {arXiv},
arxivId = {1805.01727},
author = {Badia, Santiago and Martin, Alberto F. and Verdugo, Francesc},
doi = {10.1137/18M1185624},
eprint = {1805.01727},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Badia, Mart{\'{i}}n, Verdugo - 2018 - Mixed aggregated finite element methods for the unfitted discretization of the Stokes problem.pdf:pdf},
issn = {1064-8275},
journal = {SIAM Journal on Scientific Computing},
keywords = {Q1},
mendeley-tags = {Q1},
month = {jan},
number = {6},
pages = {B1541--B1576},
title = {{Mixed Aggregated Finite Element Methods for the Unfitted Discretization of the Stokes Problem}},
url = {http://arxiv.org/abs/1805.01727 https://epubs.siam.org/doi/10.1137/18M1185624},
volume = {40},
year = {2018}
}
@article{Kohler2017,
abstract = {Cardiac 4D PC-MRI acquisitions gained increasing clinical interest in recent years. They allow to non-invasively obtain extensive information about patient-specific hemodynamics and thus have a great potential to improve the diagnosis of cardiovascular diseases. A dataset contains time-resolved, three-dimensional blood flow directions and strengths, facilitating comprehensive qualitative and quantitative data analysis. The quantification of measures such as stroke volumes helps to assess the cardiac function and monitor disease progression. Qualitative analysis allows to investigate abnormal flow characteristics, such as vortices, that are correlated to different pathologies. Processing the data comprises complex image processing methods as well as flow analysis and visualization. In this work, we mainly focus on the aorta. We provide an overview from data measurement and preprocessing to current visualization and quantification methods so that other researchers can quickly catch up with the topic and take on new challenges to further investigate the potential of 4D PC-MRI.},
author = {K{\"{o}}hler, Benjamin and Born, Silvia and van Pelt, Roy F.P. and Hennemuth, Anja and Preim, Uta and Preim, Bernhard},
doi = {10.1111/cgf.12803},
file = {:home/fverdugo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/K{\"{o}}hler et al. - 2017 - A Survey of Cardiac 4D PC-MRI Data Processing.pdf:pdf},
isbn = {978-3-905674-82-8},
issn = {14678659},
journal = {Computer Graphics Forum},
keywords = {4D PC-MRI,I.4.9 [Computing Methodologies]: Image Processing,aorta,cardiovascular diseases,data processing,survey},
number = {6},
pages = {5--35},
title = {{A Survey of Cardiac 4D PC-MRI Data Processing}},
volume = {36},
year = {2017}
}
